{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Zr9wuxDfzcYG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "from scipy import sparse\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Preparation**"
      ],
      "metadata": {
        "id": "8nXfzAnT_f6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the path to your dataset folder\n",
        "dataset_path = \"/content/drive/MyDrive/Research/esn/Audio dataset\"\n",
        "\n",
        "# Prepare an empty list to store metadata\n",
        "metadata = []\n",
        "\n",
        "# Walk through each subdirectory in the dataset folder\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        if file.endswith(\".wav\"):  # Adjust the extension if necessary\n",
        "            # Get the full file path\n",
        "            file_path = os.path.join(root, file)\n",
        "\n",
        "            # Extract class label (assumes subfolder name is the class label)\n",
        "            class_label = os.path.basename(root)\n",
        "            encoded_class_label = -99999\n",
        "            if class_label == \"rope\":\n",
        "                encoded_class_label = 0\n",
        "            elif class_label == \"chair\":\n",
        "                encoded_class_label = 1\n",
        "            elif class_label == \"clothes\":\n",
        "                encoded_class_label = 2\n",
        "            elif class_label == \"batteries\":\n",
        "                encoded_class_label = 3\n",
        "            elif class_label == \"paper\":\n",
        "                encoded_class_label = 4\n",
        "\n",
        "            # Append metadata information\n",
        "            metadata.append({\n",
        "                \"filename\": file,\n",
        "                \"filepath\": file_path,\n",
        "                \"class_label\": class_label,\n",
        "                \"encoded_class_label\": encoded_class_label\n",
        "            })\n",
        "\n",
        "# Convert metadata to a pandas DataFrame\n",
        "metadata_df = pd.DataFrame(metadata)\n",
        "\n",
        "# Save the metadata as a CSV file\n",
        "metadata_csv_path = \"audio_metadata_full.csv\"\n",
        "metadata_df.to_csv(metadata_csv_path, index=False)\n",
        "\n",
        "print(f\"Metadata CSV created at: {metadata_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNgZD876_OHO",
        "outputId": "0eacc676-2115-48a7-9d52-efb3ef9079fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata CSV created at: audio_metadata_full.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4c_tBEVLTbUS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class AudioPreprocessingPipeline(Dataset):\n",
        "    def __init__(self, metadata_file, audio_dir, sample_rate=16000, fixed_length=2.0, n_mels=64, augmentation=False):\n",
        "        \"\"\"\n",
        "        Initialize the audio preprocessing pipeline.\n",
        "\n",
        "        Args:\n",
        "            metadata_file (str): Path to the metadata CSV file.\n",
        "            audio_dir (str): Path to the directory containing audio files.\n",
        "            sample_rate (int): Target sample rate for audio.\n",
        "            fixed_length (float): Target duration (in seconds) for each audio sample.\n",
        "            n_mels (int): Number of Mel bands for the Mel spectrogram.\n",
        "            augmentation (bool): Whether to apply audio augmentation.\n",
        "        \"\"\"\n",
        "        self.metadata = pd.read_csv(metadata_file)\n",
        "        #drop class_label column\n",
        "        self.metadata = self.metadata.drop(columns=['class_label'])\n",
        "        self.audio_dir = audio_dir\n",
        "        # print(\"Audio directory: \", audio_dir)\n",
        "        self.sample_rate = sample_rate\n",
        "        self.fixed_length = fixed_length\n",
        "        self.n_mels = n_mels\n",
        "        self.augmentation = augmentation\n",
        "        self.fixed_length_samples = int(fixed_length * sample_rate)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get metadata for the current sample\n",
        "        row = self.metadata.iloc[idx]\n",
        "        filename = row['filename']\n",
        "        # print(\"Filename: \", filename)\n",
        "        class_label = row['encoded_class_label']\n",
        "        # print(\"Class label: \", class_label)\n",
        "\n",
        "        # Load audio file\n",
        "        file_path = row['filepath']\n",
        "        # print(\"File path: \", file_path)\n",
        "        audio, sr = librosa.load(file_path, sr=self.sample_rate, mono=True)\n",
        "\n",
        "        # Trim or pad audio to fixed length\n",
        "        audio = self._resize_audio(audio)\n",
        "\n",
        "        # Apply time-shifting augmentation (if enabled)\n",
        "        if self.augmentation:\n",
        "            audio = self._time_shift(audio)\n",
        "\n",
        "        # Convert to Mel spectrogram\n",
        "        mel_spectrogram = self._compute_mel_spectrogram(audio)\n",
        "\n",
        "        # Normalize Mel spectrogram\n",
        "        mel_spectrogram = self._normalize(mel_spectrogram)\n",
        "\n",
        "        # Return the spectrogram and label\n",
        "        return torch.tensor(mel_spectrogram, dtype=torch.float32), torch.tensor(class_label, dtype=torch.long)\n",
        "\n",
        "    def _resize_audio(self, audio):\n",
        "        \"\"\"Trim or pad audio to the fixed length.\"\"\"\n",
        "        if len(audio) > self.fixed_length_samples:\n",
        "            audio = audio[:self.fixed_length_samples]\n",
        "        else:\n",
        "            padding = self.fixed_length_samples - len(audio)\n",
        "            audio = np.pad(audio, (0, padding), mode='constant')\n",
        "        return audio\n",
        "\n",
        "    def _time_shift(self, audio):\n",
        "        \"\"\"Apply time-shifting augmentation.\"\"\"\n",
        "        shift = random.randint(-int(0.1 * self.sample_rate), int(0.1 * self.sample_rate))\n",
        "        audio = np.roll(audio, shift)\n",
        "        return audio\n",
        "\n",
        "    def _compute_mel_spectrogram(self, audio):\n",
        "        \"\"\"Convert audio to Mel spectrogram.\"\"\"\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(\n",
        "            y=audio, sr=self.sample_rate, n_mels=self.n_mels, fmax=self.sample_rate // 2\n",
        "        )\n",
        "        return librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "\n",
        "    def _normalize(self, spectrogram):\n",
        "        \"\"\"Normalize spectrogram to range [0, 1].\"\"\"\n",
        "        return (spectrogram - spectrogram.min()) / (spectrogram.max() - spectrogram.min())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pen3SATKvAyb",
        "outputId": "b31ec78e-fd87-4e64-e984-360573287c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mel Spectrogram Shape:  torch.Size([64, 63])\n",
            "Mel Spectrogram:\n",
            " tensor([[0.6677, 0.7462, 0.7762,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.5645, 0.6428, 0.6820,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.5661, 0.6331, 0.6327,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.2933, 0.3560, 0.3575,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.3047, 0.3509, 0.3533,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.2482, 0.3119, 0.3188,  ..., 0.0000, 0.0000, 0.0000]])\n",
            "Label: tensor(1)\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    metadata_file = \"/content/audio_metadata_full.csv\"\n",
        "    audio_dir = dataset_path\n",
        "\n",
        "    # Create dataset instance\n",
        "    dataset = AudioPreprocessingPipeline(\n",
        "        metadata_file=metadata_file,\n",
        "        audio_dir=audio_dir,\n",
        "        sample_rate=16000,\n",
        "        fixed_length=2.0,\n",
        "        n_mels=64,\n",
        "        augmentation=False\n",
        "    )\n",
        "\n",
        "    # Example: Access the first sample\n",
        "    mel_spectrogram, label = dataset[15]\n",
        "    print(\"Mel Spectrogram Shape: \", mel_spectrogram.shape)\n",
        "    print(\"Mel Spectrogram:\\n\", mel_spectrogram)\n",
        "    print(\"Label:\", label)\n",
        "    # Visualize the Mel spectrogram\n",
        "    # visualize_mel_spectrogram(mel_spectrogram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrBXbEB9q8TZ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create the dataset\n",
        "metadata_file = \"/content/audio_metadata_full.csv\"  # Replace with your metadata file\n",
        "audio_dir = dataset_path      # Replace with your audio directory\n",
        "dataset = AudioPreprocessingPipeline(metadata_file, audio_dir, augmentation=True)\n",
        "\n",
        "# Create the DataLoader\n",
        "batch_size = 5000\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Example: Iterate over batches\n",
        "for batch in data_loader:\n",
        "    mel_spectrograms, labels = batch\n",
        "    print(\"Batch Mel Spectrogram Shape:\", mel_spectrograms.shape)\n",
        "    # print(\"Batch Labels:\", labels)\n",
        "    break\n",
        "\n",
        "# Create a train_data dictionary with mel_spectograms and labels\n",
        "# train_data = {'mel_spectrogram': mel_spectrograms, 'label': labels}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mel_spectrograms.shape"
      ],
      "metadata": {
        "id": "FuB3IgsaxVXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ESN Implementation**"
      ],
      "metadata": {
        "id": "GktaFhRD_2Fn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQuFM256M3j7"
      },
      "outputs": [],
      "source": [
        "class Reservoir(object):\n",
        "    \"\"\"\n",
        "    Build a reservoir and evaluate internal states\n",
        "\n",
        "    Parameters:\n",
        "        n_internal_units = processing units in the reservoir\n",
        "        spectral_radius = largest eigenvalue of the reservoir matrix of connection weights\n",
        "        leak = amount of leakage in the reservoir state update (optional)\n",
        "        connectivity = percentage of nonzero connection weights (unused in circle reservoir)\n",
        "        input_scaling = scaling of the input connection weights\n",
        "        noise_level = deviation of the Gaussian noise injected in the state update\n",
        "        circle = generate determinisitc reservoir with circle topology\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_internal_units=100, spectral_radius=0.99, leak=None,\n",
        "                 connectivity=0.3, input_scaling=0.2, noise_level=0.01, circle=False):\n",
        "\n",
        "        # Initialize attributes\n",
        "        self._n_internal_units = n_internal_units\n",
        "        self._input_scaling = input_scaling\n",
        "        self._noise_level = noise_level\n",
        "        self._leak = leak\n",
        "\n",
        "        # Input weights depend on input size: they are set when data is provided\n",
        "        self._input_weights = None\n",
        "\n",
        "        # Generate internal weights\n",
        "        if circle:\n",
        "            self._internal_weights = self._initialize_internal_weights_Circ(\n",
        "                    n_internal_units,\n",
        "                    spectral_radius)\n",
        "        else:\n",
        "            self._internal_weights = self._initialize_internal_weights(\n",
        "                n_internal_units,\n",
        "                connectivity,\n",
        "                spectral_radius)\n",
        "\n",
        "\n",
        "    def _initialize_internal_weights_Circ(self, n_internal_units, spectral_radius):\n",
        "\n",
        "        internal_weights = np.zeros((n_internal_units, n_internal_units))\n",
        "        internal_weights[0,-1] = spectral_radius\n",
        "        for i in range(n_internal_units-1):\n",
        "            internal_weights[i+1,i] = spectral_radius\n",
        "\n",
        "        return internal_weights\n",
        "\n",
        "\n",
        "    def _initialize_internal_weights(self, n_internal_units,\n",
        "                                     connectivity, spectral_radius):\n",
        "\n",
        "        # Generate sparse, uniformly distributed weights.\n",
        "        internal_weights = sparse.rand(n_internal_units,\n",
        "                                       n_internal_units,\n",
        "                                       density=connectivity).todense()\n",
        "\n",
        "        # Ensure that the nonzero values are uniformly distributed in [-0.5, 0.5]\n",
        "        internal_weights[np.where(internal_weights > 0)] -= 0.5\n",
        "\n",
        "        # Adjust the spectral radius.\n",
        "        E, _ = np.linalg.eig(internal_weights)\n",
        "        e_max = np.max(np.abs(E))\n",
        "        internal_weights /= np.abs(e_max)/spectral_radius\n",
        "        print(internal_weights.shape)\n",
        "        return internal_weights\n",
        "\n",
        "\n",
        "    def _compute_state_matrix(self, X, n_drop=0):\n",
        "        N, T, _ = X.shape\n",
        "        previous_state = np.zeros((N, self._n_internal_units), dtype=float)\n",
        "\n",
        "        # Storage\n",
        "        state_matrix = np.empty((N, T - n_drop, self._n_internal_units), dtype=float)\n",
        "        for t in range(T):\n",
        "            current_input = X[:, t, :]\n",
        "\n",
        "            # Calculate state\n",
        "            state_before_tanh = self._internal_weights.dot(previous_state.T) + self._input_weights.dot(current_input.T)\n",
        "\n",
        "            # Add noise\n",
        "            state_before_tanh += np.random.rand(self._n_internal_units, N)*self._noise_level\n",
        "\n",
        "            # Apply nonlinearity and leakage (optional)\n",
        "            if self._leak is None:\n",
        "                previous_state = np.tanh(state_before_tanh).T\n",
        "            else:\n",
        "                previous_state = (1.0 - self._leak)*previous_state + np.tanh(state_before_tanh).T\n",
        "\n",
        "            # Store everything after the dropout period\n",
        "            if (t > n_drop - 1):\n",
        "                state_matrix[:, t - n_drop, :] = previous_state\n",
        "\n",
        "        return state_matrix\n",
        "\n",
        "\n",
        "    def get_states(self, X, n_drop=0, bidir=True):\n",
        "        N, T, V = X.shape\n",
        "        if self._input_weights is None:\n",
        "            self._input_weights = (2.0*np.random.binomial(1, 0.5 , [self._n_internal_units, V]) - 1.0)*self._input_scaling\n",
        "\n",
        "        # compute sequence of reservoir states\n",
        "        states = self._compute_state_matrix(X, n_drop)\n",
        "\n",
        "        # reservoir states on time reversed input\n",
        "        if bidir is True:\n",
        "            X_r = X[:, ::-1, :]\n",
        "            states_r = self._compute_state_matrix(X_r, n_drop)\n",
        "            states = np.concatenate((states, states_r), axis=2)\n",
        "\n",
        "        return states\n",
        "\n",
        "    def getReservoirEmbedding(self, X,pca, ridge_embedding,  n_drop=5, bidir=True, test = False):\n",
        "\n",
        "        res_states = self.get_states(X, n_drop=5, bidir=True)\n",
        "\n",
        "\n",
        "        N_samples = res_states.shape[0]\n",
        "        res_states = res_states.reshape(-1, res_states.shape[2])\n",
        "        # ..transform..\n",
        "        if test:\n",
        "            red_states = pca.transform(res_states)\n",
        "        else:\n",
        "            red_states = pca.fit_transform(res_states)\n",
        "        # ..and put back in tensor form\n",
        "        red_states = red_states.reshape(N_samples,-1,red_states.shape[1])\n",
        "\n",
        "        coeff_tr = []\n",
        "        biases_tr = []\n",
        "\n",
        "        for i in range(X.shape[0]):\n",
        "            ridge_embedding.fit(red_states[i, 0:-1, :], red_states[i, 1:, :])\n",
        "            coeff_tr.append(ridge_embedding.coef_.ravel())\n",
        "            biases_tr.append(ridge_embedding.intercept_.ravel())\n",
        "        print(np.array(coeff_tr).shape,np.array(biases_tr).shape)\n",
        "        input_repr = np.concatenate((np.vstack(coeff_tr), np.vstack(biases_tr)), axis=1)\n",
        "        return input_repr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = mel_spectrograms\n",
        "y = labels\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "x3gZHq0fAFPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = scipy.io.loadmat('/content/JpVow.mat')\n",
        "# print(data['X'].shape)\n",
        "# print(data['Y'].shape)\n",
        "# print(data['Xte'].shape)\n",
        "# print(data['Yte'].shape)\n",
        "\n",
        "# print(\" ================================\")\n",
        "# print(X_train.numpy().shape)\n",
        "# print(y_train.numpy().shape)\n",
        "# print(X_test.numpy().shape)\n",
        "# print(y_test.numpy().shape)"
      ],
      "metadata": {
        "id": "0PhgyR8fyX7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train.numpy().reshape(-1,1).shape"
      ],
      "metadata": {
        "id": "GtINoQXdzCw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnU2iJH6NaXd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# X = data['X']\n",
        "# Y = data['Y']\n",
        "# Xte = data['Xte']\n",
        "# Yte = data['Yte']\n",
        "\n",
        "# # One-hot encoding for labels\n",
        "# onehot_encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
        "# Y = onehot_encoder.fit_transform(Y)\n",
        "# Yte = onehot_encoder.transform(Yte)\n",
        "\n",
        "X = X_train.numpy()\n",
        "Y = y_train.numpy().reshape(-1,1)\n",
        "Xte = X_test.numpy()\n",
        "Yte = y_test.numpy().reshape(-1,1)\n",
        "\n",
        "# One-hot encoding for labels\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
        "Y = onehot_encoder.fit_transform(Y)\n",
        "Yte = onehot_encoder.transform(Yte)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnvSpcG_OGu5"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=30)\n",
        "ridge_embedding = Ridge(alpha=6, fit_intercept=True)\n",
        "readout = Ridge(alpha=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeUAUW4XOLql"
      },
      "outputs": [],
      "source": [
        "res = Reservoir(n_internal_units=30, spectral_radius=0.6, leak=0.6,\n",
        "                 connectivity=0.25, input_scaling=0.1, noise_level=0.01, circle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21DDL_J6OVGV"
      },
      "outputs": [],
      "source": [
        "input_repr = res.getReservoirEmbedding(X,pca, ridge_embedding,  n_drop=5, bidir=True, test = False)\n",
        "input_repr_te = res.getReservoirEmbedding(Xte,pca, ridge_embedding,  n_drop=5, bidir=True, test = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOImu2f6OdTA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# from sklearn.metrics import accuracy_score, f1_score\n",
        "readout.fit(input_repr, Y)\n",
        "logits = readout.predict(input_repr_te)\n",
        "# prediction = tf.nn.softmax(logits)\n",
        "# logits = logits.reshape(-1, 1)\n",
        "pred_class = np.argmax(logits, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "id": "DC6874cms510"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# true_class = Yte\n",
        "true_class = np.argmax(Yte, axis=1)"
      ],
      "metadata": {
        "id": "iDqmf5JTFFjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_class.shape"
      ],
      "metadata": {
        "id": "sfTPvb5kt5FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_class.shape"
      ],
      "metadata": {
        "id": "rsyarzrwt8Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqO4JNYqOjVm"
      },
      "outputs": [],
      "source": [
        "accuracy_score(true_class, pred_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRSW2o3zOkZg"
      },
      "outputs": [],
      "source": [
        "f1_score(true_class, pred_class, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Result Analysis Section\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Calculate accuracy and F1 score\n",
        "accuracy = accuracy_score(true_class, pred_class)\n",
        "f1 = f1_score(true_class, pred_class, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Weighted F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "num_classes = len(set(true_class))  # Dynamically determine the number of classes\n",
        "report = classification_report(true_class, pred_class, target_names=[f\"Class {i}\" for i in range(num_classes)])\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(report)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(true_class, pred_class, labels=range(num_classes))\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[f\"Class {i}\" for i in range(num_classes)], yticklabels=[f\"Class {i}\" for i in range(num_classes)])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()\n",
        "\n",
        "# Visualize Class-wise Metrics\n",
        "class_wise_metrics = classification_report(true_class, pred_class, output_dict=True)\n",
        "class_names = list(class_wise_metrics.keys())[:-3]\n",
        "precision = [class_wise_metrics[cls]['precision'] for cls in class_names]\n",
        "recall = [class_wise_metrics[cls]['recall'] for cls in class_names]\n",
        "f1_scores = [class_wise_metrics[cls]['f1-score'] for cls in class_names]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "bar_width = 0.25\n",
        "x = range(len(class_names))\n",
        "\n",
        "plt.bar(x, precision, width=bar_width, label='Precision')\n",
        "plt.bar([i + bar_width for i in x], recall, width=bar_width, label='Recall')\n",
        "plt.bar([i + 2 * bar_width for i in x], f1_scores, width=bar_width, label='F1-Score')\n",
        "\n",
        "plt.xticks([i + bar_width for i in x], class_names)\n",
        "plt.title(\"Class-wise Metrics\")\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Scores\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# If training metrics are available, plot them\n",
        "# For example:\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# plt.plot(train_accuracy, label='Training Accuracy')\n",
        "# plt.plot(test_accuracy, label='Testing Accuracy')\n",
        "# plt.title(\"Training vs. Testing Accuracy\")\n",
        "# plt.xlabel(\"Epochs\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "# plt.legend()\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "gDcddEcVFC0z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}